{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook (Reproducible)\n\nThis notebook reproduces the findings summarized in `data/raw/DATA_EXPLORATION_SUMMARY.md`. Run each section to regenerate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Environment and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src to path\n",
    "ROOT = Path.cwd().parents[0] if (Path.cwd().name == 'notebooks') else Path.cwd()\n",
    "if (ROOT / 'src').exists():\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "from src.config import NUM_PARTICLES, NUM_FEATURES, FEATURE_NAMES, DATASET_FILES\n",
    "\n",
    "print('Environment ready')\n",
    "print('NUM_PARTICLES:', NUM_PARTICLES)\n",
    "print('NUM_FEATURES:', NUM_FEATURES)\n",
    "print('FEATURE_NAMES:', FEATURE_NAMES)\n",
    "print('DATASET_FILES configured:', len(DATASET_FILES))\n",
    "print('numpy:', np.__version__)\n",
    "print('pandas:', pd.__version__)\n",
    "print('h5py:', h5py.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dataset Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ROOT / 'data' / 'raw'\n",
    "print('Looking in:', data_dir)\n",
    "avail = []\n",
    "for fn in DATASET_FILES:\n",
    "    p = data_dir / fn\n",
    "    print(('✅' if p.exists() else '❌'), fn, ('(' + str(round(p.stat().st_size/1024/1024,1)) + ' MB)') if p.exists() else '(missing)')\n",
    "    if p.exists():\n",
    "        avail.append(p)\n",
    "print(f'Found {len(avail)} / {len(DATASET_FILES)} files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) HDF5 Structure (Representative File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = avail[0] if avail else None\n",
    "print('Representative file:', rep.name if rep else 'None')\n",
    "if rep:\n",
    "    with h5py.File(rep, 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        print('Top-level keys:', keys)\n",
    "        def show(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                size_mb = obj.size * obj.dtype.itemsize / 1024/1024\n",
    "                print(f' - {name}: shape={obj.shape}, dtype={obj.dtype}, ~{size_mb:.2f} MB')\n",
    "        f.visititems(show)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Physics Parameter Parsing from Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'mZprime-(?P<mZprime>\\d+)_mDark-(?P<mDark>\\d+)_rinv-(?P<rinv>0\\.\\d+)_alpha-(?P<alpha>\\w+)')\n",
    "rows = []\n",
    "for p in avail:\n",
    "    fn = p.name\n",
    "    if 'NominalSM' in fn:\n",
    "        rows.append({'filename': fn, 'mZprime': None, 'mDark': None, 'rinv': None, 'alpha': 'SM'})\n",
    "    else:\n",
    "        m = pattern.search(fn)\n",
    "        if m:\n",
    "            d = m.groupdict()\n",
    "            d['mZprime'] = int(d['mZprime'])\n",
    "            d['mDark'] = int(d['mDark'])\n",
    "            d['rinv'] = float(d['rinv'])\n",
    "            d['filename'] = fn\n",
    "            rows.append(d)\n",
    "df = pd.DataFrame(rows)\n",
    "display(df)\n",
    "for col in ['mZprime','mDark','rinv','alpha']:\n",
    "    if col in df.columns:\n",
    "        print(col, sorted(df[col].dropna().unique().tolist()))\n",
    "print('Counts: total files', len(df), '| signal', (df['alpha']!='SM').sum(), '| background', (df['alpha']=='SM').sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Single-File Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if rep:\n",
    "    with h5py.File(rep, 'r') as f:\n",
    "        n = f['jet_pt'].shape[0] if 'jet_pt' in f else None\n",
    "        dark = f['jet_is_dark'][:] if 'jet_is_dark' in f else None\n",
    "        n_dark = int(dark.sum()) if dark is not None else None\n",
    "        print('Total jets:', n)\n",
    "        if n_dark is not None:\n",
    "            print('Dark jets:', n_dark, f'({n_dark/n*100:.1f}%)')\n",
    "        if 'particle_features' in f:\n",
    "            pf = f['particle_features'][:]\n",
    "            print('particle_features shape:', pf.shape)\n",
    "            arr = pf.reshape(-1, NUM_PARTICLES, NUM_FEATURES)\n",
    "            invalid = np.isclose(arr, -999).any(axis=2)\n",
    "            valid_frac = 1.0 - invalid.mean()\n",
    "            print('Estimated valid particle fraction (sample):', f'{valid_frac:.3f}')\n",
    "        for k in ['jet_pt','jet_eta','jet_phi','jet_m','jet_e','jet_rinv']:\n",
    "            if k in f:\n",
    "                print(k, f[k].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Feature Distributions Across Files (valid particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pf(p):\n",
    "    with h5py.File(p, 'r') as f:\n",
    "        pf = f['particle_features'][:]\n",
    "        is_dark = f['jet_is_dark'][:] if 'jet_is_dark' in f else None\n",
    "        return pf, is_dark\n",
    "\n",
    "sig_pT = []; sig_eta = []; sig_phi = []\n",
    "sm_pT = []; sm_eta = []; sm_phi = []\n",
    "for p in avail:\n",
    "    pf, is_dark = load_pf(p)\n",
    "    arr = pf.reshape(-1, NUM_PARTICLES, NUM_FEATURES)\n",
    "    invalid = np.isclose(arr, -999).any(axis=2)\n",
    "    valid = ~invalid\n",
    "    if 'NominalSM' in p.name:\n",
    "        sm_pT.append(arr[:,:,0][valid])\n",
    "        sm_eta.append(arr[:,:,1][valid])\n",
    "        sm_phi.append(arr[:,:,2][valid])\n",
    "    else:\n",
    "        if is_dark is not None:\n",
    "            vm = valid[is_dark]  # only dark jets\n",
    "            arr_d = arr[is_dark]\n",
    "            sig_pT.append(arr_d[:,:,0][vm])\n",
    "            sig_eta.append(arr_d[:,:,1][vm])\n",
    "            sig_phi.append(arr_d[:,:,2][vm])\n",
    "sig = {'pT': np.concatenate(sig_pT), 'eta': np.concatenate(sig_eta), 'phi': np.concatenate(sig_phi)}\n",
    "sm  = {'pT': np.concatenate(sm_pT),  'eta': np.concatenate(sm_eta),  'phi': np.concatenate(sm_phi)}\n",
    "\n",
    "def describe(v):\n",
    "    v = v[np.isfinite(v)]\n",
    "    return dict(count=int(v.size), mean=float(v.mean()), std=float(v.std()), min=float(v.min()), max=float(v.max()))\n",
    "\n",
    "for ftr in ['pT','eta','phi']:\n",
    "    ds = describe(sig[ftr]); db = describe(sm[ftr])\n",
    "    print(ftr, 'Signal', ds, '| SM', db)\n",
    "# Optionally plot (density)\n",
    "plt.figure(); plt.hist(sm['pT'], bins=100, density=True, alpha=0.6, label='SM'); plt.hist(sig['pT'], bins=100, density=True, alpha=0.6, label='Signal'); plt.legend(); plt.title('pT (valid particles)'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Jet-level Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JET_KEYS = ['jet_pt','jet_eta','jet_phi','jet_m','jet_e']\n",
    "sig = {k: [] for k in JET_KEYS}\n",
    "sm = {k: [] for k in JET_KEYS}\n",
    "for p in avail:\n",
    "    with h5py.File(p, 'r') as f:\n",
    "        is_sm = 'NominalSM' in p.name\n",
    "        is_dark = f['jet_is_dark'][:] if 'jet_is_dark' in f else None\n",
    "        for k in JET_KEYS:\n",
    "            if k not in f: continue\n",
    "            arr = f[k][:]\n",
    "            if is_sm:\n",
    "                sm[k].append(arr)\n",
    "            else:\n",
    "                if is_dark is None: continue\n",
    "                sig[k].append(arr[is_dark])\n",
    "sig = {k: np.concatenate(v) for k,v in sig.items()}\n",
    "sm  = {k: np.concatenate(v) for k,v in sm.items()}\n",
    "\n",
    "def d(v):\n",
    "    v = v[np.isfinite(v)]\n",
    "    return dict(count=int(v.size), mean=float(v.mean()), std=float(v.std()), min=float(v.min()), max=float(v.max()))\n",
    "\n",
    "for k in JET_KEYS:\n",
    "    print(k, 'Signal', d(sig[k]), '| SM', d(sm[k]))\n",
    "# Example plot\n",
    "plt.figure(); plt.hist(sm['jet_pt'], bins=100, density=True, alpha=0.6, label='SM'); plt.hist(sig['jet_pt'], bins=100, density=True, alpha=0.6, label='Signal'); plt.legend(); plt.title('jet_pt (jets)'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n- Histograms are plotted with `density=True` to compare shapes irrespective of different sample sizes.\n- No training merges/splits are performed here; these are analysis-only aggregates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
